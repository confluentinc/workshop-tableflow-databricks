# ShadowTraffic Data Configuration

This directory contains the complete ShadowTraffic data configuration for the River Hotels workshop, including generators, schemas, connections, and the main configuration file. The setup uses ShadowTraffic's modular approach with the [`loadJsonFile` feature](https://docs.shadowtraffic.io/functions/loadJsonFile/) for maintainable and reusable data generation.

## Directory Structure

```sh
data/
├── shadow-traffic-configuration.json    # Main configuration file
├── shadow-traffic-license.env          # License environment variables
├── generators/                         # Data generator configurations
│   ├── customer_generator.json
│   ├── hotel_generator.json
│   ├── clickstream_generator_historical.json
│   ├── clickstream_generator_streaming.json
│   ├── booking_generator_historical.json
│   ├── booking_generator_streaming.json
│   ├── review_generator_historical.json
│   ├── review_generator_streaming.json
│   ├── review_text_choices_1_star.json
│   ├── review_text_choices_2_star.json
│   ├── review_text_choices_3_star.json
│   ├── review_text_choices_4_star.json
│   └── review_text_choices_5_star.json
├── schemas/                           # Avro schema definitions
│   ├── booking_schema.avsc
│   ├── clickstream_schema.avsc
│   └── review_schema.avsc
└── connections/                       # Connection configurations (populated by Terraform)
```

## Configuration Files

### Main Configuration

- **`shadow-traffic-configuration.json`** - Orchestrates all generators using a three-stage approach: seed data → historical data → streaming data
- **`shadow-traffic-license.env`** - Contains ShadowTraffic license environment variables (auto-generated by Terraform)

### Terraform-Managed Files

Several critical files are automatically generated and destroyed by Terraform during infrastructure provisioning:

#### Auto-Generated Files

- **`connections/oracle.json`** - Oracle database connection with dynamic host IP and credentials
- **`connections/confluent.json`** - Confluent Cloud connection with API keys, bootstrap servers, and schema registry URLs
- **`shadow-traffic-license.env`** - ShadowTraffic license downloaded from GitHub

#### Why Terraform Management?

These files require numerous resource values and IDs from other Terraform-managed cloud resources (AWS instances, Confluent clusters, API keys, etc.) that need to be dynamically interpolated. Rather than requiring manual configuration with complex resource references, Terraform automatically:

1. **Generates** these files during `terraform apply` with proper resource interpolation
2. **Destroys** these files during `terraform destroy` for clean teardown
3. **Updates** connection details if infrastructure changes

This approach eliminates manual configuration errors and ensures the ShadowTraffic configuration always has current, valid connection information from the actual provisioned resources.

## Generators

### Data Source Generators

#### Oracle Database Generators

- **`customer_generator.json`** - Generates 1,000 customer records with contact information
- **`hotel_generator.json`** - Generates 30 hotel properties across 9 countries with amenities and descriptions

#### Kafka Topic Generators

- **`clickstream_generator_historical.json`** - Generates 3,000 historical website interaction events over the past 8 weeks
- **`clickstream_generator_streaming.json`** - Produces real-time clickstream events every 10-15 seconds
- **`booking_generator_historical.json`** - Generates 400 historical booking records with realistic date relationships
- **`booking_generator_streaming.json`** - Produces streaming booking events every 45-60 seconds
- **`review_generator_historical.json`** - Generates 200 historical hotel reviews with unique booking references (B600000100-B600000299)
- **`review_generator_streaming.json`** - Produces streaming reviews every 100-150 seconds with unique booking references (B600000300-B600000309)

### Review Text Resources

Rating-specific review text files ensure sentiment matches numeric ratings:

- **`review_text_choices_1_star.json`** - Very bad experiences (10% frequency)
- **`review_text_choices_2_star.json`** - Somewhat bad experiences (20% frequency)
- **`review_text_choices_3_star.json`** - OK experiences (30% frequency)
- **`review_text_choices_4_star.json`** - Pretty good experiences (25% frequency)
- **`review_text_choices_5_star.json`** - Great experiences (15% frequency)

## Schemas

Avro schema files define the structure for Kafka topics and ensure type safety:

### `booking_schema.avsc`

Defines the booking event structure with fields:

- `BOOKING_ID`, `CUSTOMER_EMAIL`, `HOTEL_ID`
- `CHECK_IN`, `CHECK_OUT`, `OCCUPANTS`, `PRICE`
- `CREATED_AT` (with Flink timestamp precision)

### `clickstream_schema.avsc`

Defines website interaction events with fields:

- `ACTIVITY_ID`, `CUSTOMER_EMAIL`, `HOTEL_ID`
- `ACTION`, `EVENT_DURATION`, `URL`
- `CREATED_AT` (with Flink timestamp precision)

### `review_schema.avsc`

Defines hotel review events with fields:

- `REVIEW_ID`, `BOOKING_ID`
- `REVIEW_RATING`, `REVIEW_TEXT`
- `CREATED_AT` (with Flink timestamp precision)

## Connections

The `connections/` directory contains auto-generated connection files managed by Terraform:

### Connection Files

- **`oracle.json`** - Oracle database connection for customer and hotel data with dynamic AWS EC2 instance details
- **`confluent.json`** - Confluent Cloud connection for Kafka topic streaming with live API keys and cluster endpoints

### Terraform Integration

These connection files are automatically managed through the Terraform lifecycle:

```hcl
# Example from data_generator.tf
resource "local_file" "oracle_connection_config" {
  content = jsonencode({
    kind: "oracle"
    connectionConfigs: {
      host: "${aws_instance.oracle_instance.public_ip}"
      port: "${var.oracle_db_port}"
      # ... other dynamic values
    }
  })
  filename = "../data/connections/oracle.json"
}
```

#### Benefits

- **Dynamic Values**: Automatically includes actual resource IDs, IPs, and API keys from provisioned infrastructure
- **No Manual Updates**: Connection details stay current as infrastructure changes
- **Clean Lifecycle**: Files are created during `terraform apply` and removed during `terraform destroy`
- **Error Prevention**: Eliminates manual transcription errors between Terraform outputs and ShadowTraffic configuration

## Key Features

### Advanced Data Generation

- **Variable-based Date Logic**: Booking generators ensure `CHECK_OUT` is 2-5 days after `CHECK_IN`
- **Realistic Booking Patterns**: Historical bookings created 2-21 days before `CHECK_IN`
- **Unique Booking References**: Reviews use sequential booking ID references to ensure no duplicate reviews per booking
- **Customer Behavior Modeling**: 80% of activities/bookings from repeat customers
- **Timestamp Formatting**: All date fields use proper formatting with `decimals: 0`
- **Master Data Timing**: Customer and hotel data generated in memory but delayed 15 minutes before Oracle insertion, simulating master data propagation timing

### Unique Booking ID Constraint in Hotel Reviews

To ensure data integrity, the review generators implement a unique constraint on `BOOKING_ID` references by using sequential generation instead of random lookups.

#### The Challenge with Random Lookups

ShadowTraffic's `lookup` function performs **random sampling with replacement**, meaning:

```json
// This approach allows duplicates!
"BOOKING_ID": {
    "_gen": "lookup",
    "name": "booking_generator_historical",
    "path": ["value", "BOOKING_ID"]
}
```

**Example Scenario**:
- Review 1: randomly selects `B600000150` ✅
- Review 2: randomly selects `B600000200` ✅
- Review 3: randomly selects `B600000150` ❌ **DUPLICATE!**
- Review 4: randomly selects `B600000105` ✅

This violates the business constraint that each booking should have **at most one review**.

#### Workaround Solution: Sequential Non-Overlapping References

**Implementation**:

- **Historical Reviews** (200 reviews): Reference `B600000100` - `B600000299`
- **Streaming Reviews** (10 reviews): Reference `B600000300` - `B600000309`

```json
// Historical reviews
"BOOKING_ID": {
    "_gen": "sequentialString",
    "startingFrom": 600000100,
    "expr": "B~d"
}

// Streaming reviews
"BOOKING_ID": {
    "_gen": "sequentialString",
    "startingFrom": 600000300,
    "expr": "B~d"
}
```

> [!NOTE]
> **Temporary Workaround**
>
> This solution is only meant to be temporary until a viable feature, like lookups that are constrained to find unique values, becomes available in ShadowTraffic.

#### Benefits of This Approach

- ✅ **Guaranteed Uniqueness**: Each booking ID appears in exactly one review
- ✅ **Data Integrity**: Eliminates downstream processing issues from duplicate reviews
- ✅ **Realistic Business Logic**: Mirrors real-world constraint where bookings have 0 or 1 review
- ✅ **Workshop Focus**: Keeps complexity on core streaming concepts rather than data generation edge cases
- ✅ **Clear Data Lineage**: Easy to understand which bookings have reviews (first 210 of 420 total)

#### Business Impact

**Review Distribution**:

- **Total Bookings**: 420 (400 historical + 20 streaming)
- **Bookings with Reviews**: 210 (200 historical + 10 streaming)
- **Review Rate**: 50% (realistic for hospitality industry)

This creates a authentic dataset for testing stream processing, analytics, and AI workflows without data quality issues interfering with learning objectives.

### Rating-Based Review System

- **Sentiment-Rating Alignment**: Each rating (1-5 stars) has dedicated text files with matching sentiment
- **Realistic Distribution**: Weighted frequencies create believable customer feedback patterns
- **Switch-Based Selection**: Intelligent text selection based on numeric rating values

## Rating-Based Review Text System

The review generators implement a sophisticated rating-based text selection system:

### Rating Scale Implementation

| Rating | Sentiment | Frequency | Example Language |
|--------|-----------|-----------|------------------|
| 1 Star | Very bad experiences | 10% | "absolutely dreadful", "complete disaster", "appalling standards" |
| 2 Stars | Somewhat bad experiences | 20% | "disappointing aspects", "didn't quite match expectations" |
| 3 Stars | OK experiences | 30% | "perfectly adequate", "met basic expectations" |
| 4 Stars | Pretty good experiences | 25% | "very pleasant stay", "exceeded expectations" |
| 5 Stars | Great experiences | 15% | "exceptional", "outstanding", "exceeded all expectations" |

#### Distribution Notes

- **Consistent across generators**: Both historical and streaming use identical frequency distributions
- **Realistic pattern**: 4-star reviews (25%) more common than perfect 5-star reviews (15%)
- **Balanced spectrum**: Covers full range from very negative to exceptional experiences

### Technical Implementation

```json
"varsOnce": {
    "oneStarTexts": { "_gen": "loadJsonFile", "file": "review_text_choices_1_star.json" },
    "twoStarTexts": { "_gen": "loadJsonFile", "file": "review_text_choices_2_star.json" }
    // ... (3-5 star text files loaded once)
},
"value": {
    "REVIEW_RATING": {
        "_gen": "weightedOneOf",
        "choices": [
            { "weight": 10, "value": 1 },
            { "weight": 20, "value": 2 }
            // ... (weights 30, 25, 15 for ratings 3, 4, 5)
        ],
        "avroHint": { "type": "int" }
    },
    "REVIEW_TEXT": {
        "_gen": "weightedOneOf",
        "choices": [
            { "weight": 10, "value": { "_gen": "oneOf", "choices": { "_gen": "var", "var": "oneStarTexts" }}},
            { "weight": 20, "value": { "_gen": "oneOf", "choices": { "_gen": "var", "var": "twoStarTexts" }}}
            // ... (matching weights for 3-5 star texts)
        ],
        "avroHint": { "type": "string" }
    }
}
```

## Data Generation Stages

1. **Stage 0: Configuration**
   1. The `shadow-traffic-configuration.json` file contains a three-sequential-stage approach to generate both a batch of historical data and periodic ongoing streaming data
   2. Connections to Oracle and Confluent Cloud are prebuilt
2. **Stage 1: Seed Data (Oracle Database)**
   1. The `customer_generator` creates 1,000 customer records with timestamps of 10 weeks ago
      - **15-Minute Delay**: Records are generated in memory immediately but delayed 15 minutes before Oracle insertion
   2. The `hotel_generator` creates 30 hotel records across 9 countries with timestamps of 10 weeks ago
      - **15-Minute Delay**: Records are generated in memory immediately but delayed 15 minutes before Oracle insertion
3. **Stage 2: Historical Data (Kafka Topics)**
   1. **Clickstream Generator (Historical)** - Generates 3,000 clickstream events with random timestamps over the past 8 weeks
   2. **Booking Generator (Historical)** - Generates 400 booking records with random timestamps over the past 8 weeks
   3. **Review Generator (Historical)** - Generates 200 hotel reviews with unique booking references (B600000100-B600000299) and timestamps over the past 8 weeks
4. **Stage 3: Streaming Data (Kafka Topics)**
   1. **Clickstream Generator (Streaming)** - Produces messages every 10-15 seconds to the `clickstream` topic with a maximum of 125 events
      - References customer emails and hotel IDs from Oracle data
      - 80% of clickstream activity come from existing customers, 20% from anonymous users
   2. **Booking Generator (Streaming)** - Produces messages every 45-60 seconds to the `bookings` topic with a maximum of 20 events
      - Ensures that 20% of customers never appear in bookings
      - References customer emails and hotel IDs from Oracle data
   3. **Review Generator (Streaming)** - Produces messages every 100-150 seconds to the `hotel_reviews` topic up to a max of 10 events
      - Includes all review ratings from 1-5 stars with weighted distribution
      - References unique booking IDs (B600000300-B600000309) to ensure no duplicate reviews

### Timing Strategy

The practical reason for the 15-minute delay for customers and hotels data is to allow for the dockerized Oracle database to fully spin up and start accepting connections.

However, The 15-minute delay for master data (customers and hotels) can simulate a realistic data pipeline simulation where:

- **Kafka Streams** begin immediately with clickstream, booking, and review events
- **Master Data** appears in Oracle after 15 minutes, simulating typical enterprise data propagation delays
- **Lookup Operations** in Kafka consumers can demonstrate handling of missing reference data scenarios
- **Data Dependencies** mirror real-world timing where transactional events may arrive before their related master data

## Usage

### Running ShadowTraffic

Execute the data generation with this Docker command:

```sh
docker run --env-file ./data/shadow-traffic-license.env -v "$(pwd)/data/:/home/data" shadowtraffic/shadowtraffic:1.1.1 --config /home/data/shadow-traffic-configuration.json --watch
```

### Docker Command Breakdown

| Component | Purpose |
|-----------|---------|
| `docker run` | Starts a new Docker container |
| `--env-file ./data/shadow-traffic-license.env` | Loads ShadowTraffic license environment variables |
| `-v "$(pwd)/data/:/home/data"` | Mounts local `data/` directory to container for file access |
| `shadowtraffic/shadowtraffic:1.1.1` | Specifies ShadowTraffic Docker image version |
| `--config /home/data/shadow-traffic-configuration.json` | Points to main configuration file |
| `--watch` | Auto-restarts generation when config files change |

### Benefits of This Configuration

1. **Maintainability**: Modular files make individual components easy to modify
2. **Reusability**: Generators can be reused across different configurations
3. **Type Safety**: Avro schemas ensure data consistency and compatibility
4. **Realistic Data**: Rating-based text selection creates believable synthetic data
5. **Scalability**: Three-stage approach handles both historical and streaming scenarios
6. **Monitoring**: `--watch` flag enables live configuration changes

For additional CLI options and alternatives, see the [ShadowTraffic cheat sheet](https://docs.shadowtraffic.io/cheatsheet/#docker-commands).

## Business Value

This configuration generates realistic River Hotels data for testing AI-powered marketing pipelines:

- **Customer interactions** through website clickstream events
- **Booking transactions** with proper temporal relationships
- **Review feedback** with sentiment matching ratings
- **Multi-system integration** across Oracle, Kafka, and analytics platforms

The synthetic data enables comprehensive testing of real-time AI marketing systems without requiring production data or complex customer privacy considerations.
